{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IMPORT LIBRARY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:59:46.441148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 19:59:47.458017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/senume/anaconda3/envs/Person_identification_Env/lib/\n",
      "2023-03-09 19:59:47.458104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/senume/anaconda3/envs/Person_identification_Env/lib/\n",
      "2023-03-09 19:59:47.458111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/senume/Project/Research/Person-Identification-using-Chebyshev-polynomial\n"
     ]
    }
   ],
   "source": [
    "import os, warnings, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Machine learning Model \n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report,roc_curve,auc,average_precision_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Deep learning Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Directory Path Saving\n",
    "os.chdir('..')\n",
    "dir = os.getcwd()\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FUNCTION DEFINITION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def SVM(X_Dataset,Y_Dataset, X_validation, Y_validation, Coeff, Interval):\n",
    "  # Normally, C = 1 and gamma = 'scale' are default values\n",
    "  # C controls how wide the margin will be with respect to how many misclassification we are allowing\n",
    "  # C is increasing --> reduce the size of the margin and fewer misclassification and vice versa\n",
    "\n",
    "  param_grid = [\n",
    "      {'C': [0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 30, 50, 80, 100],\n",
    "      'gamma': ['scale', 0.5, 0.125, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "      'kernel': ['rbf', 'linear', 'poly', 'sigmoid']},\n",
    "  ]\n",
    "\n",
    "\n",
    "\n",
    "  optimal_params = GridSearchCV(SVC(),\n",
    "                              param_grid,\n",
    "                              scoring='f1_weighted',\n",
    "                              cv=StratifiedKFold(5))\n",
    "\n",
    "  optimal_params.fit(X_Dataset, Y_Dataset)\n",
    "  print(optimal_params.best_params_)\n",
    "\n",
    "  #svm\n",
    "  C = optimal_params.best_params_['C']\n",
    "  gamma = optimal_params.best_params_['gamma']\n",
    "  kernel = optimal_params.best_params_['kernel']\n",
    "\n",
    "  svm = SVC(C=C, gamma=gamma, kernel=kernel)\n",
    "  svm.fit(X_Dataset, Y_Dataset)\n",
    "\n",
    "  # predict the response\n",
    "  svm_y_pred = svm.predict(X_validation)\n",
    "\n",
    "  # Classification Report for the Support Vector Machine Model\n",
    "  print(\"Classification Report : Support Vector Machine\")\n",
    "  classRep = classification_report(Y_validation, svm_y_pred, digits=5)\n",
    "\n",
    "  ## Saving the Report and model\n",
    "  pickle.dump(svm, open(dir + '/Record/' + f'Model_SVM_{Coeff}_{Interval}', 'wb'))\n",
    "  np.savez_compressed(dir + '/Record/' + f'Model_SVM_Report_{Coeff}_{Interval}', Report = classRep)\n",
    "  \n",
    "\n",
    "  print(classRep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOADING DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval Type:  PP_Interval\n",
      "Chebyshev Coefficent ['20', '30', '40', '70', '50', '100', '60', '80', '90', '10']\n",
      "Reading Dataset of Chebyshev Coefficient:  10\n"
     ]
    }
   ],
   "source": [
    "Coeff_N = 9\n",
    "\n",
    "os.chdir(dir + '/Feature_Dataset')\n",
    "L = os.listdir()\n",
    "\n",
    "# For given Interval Type\n",
    "IntervalNo = 0\n",
    "os.chdir(L[IntervalNo])\n",
    "print('Interval Type: ', L[IntervalNo])\n",
    "\n",
    "# Selecting Coefficient_Count Folder \n",
    "Coeff_Fol = os.listdir()\n",
    "print(\"Chebyshev Coefficent\",Coeff_Fol)\n",
    "os.chdir(Coeff_Fol[Coeff_N])\n",
    "\n",
    "# Patient List\n",
    "PatientList =  os.listdir()\n",
    "\n",
    "# Label Specifying Each Patient\n",
    "Label = {}\n",
    "\n",
    "for n in range(0,len(PatientList)):\n",
    "    Label[PatientList[n]] = n\n",
    "\n",
    "# Spliting the Person into Family List and New Individual List\n",
    "N = len(PatientList)\n",
    "FamilyList_EndIndex = int(math.ceil((70/100)*N))\n",
    "FamilyList = PatientList[:FamilyList_EndIndex]\n",
    "NewIdividualList = PatientList[FamilyList_EndIndex:]\n",
    "\n",
    "\n",
    "# Reading Dataset\n",
    "print(\"Reading Dataset of Chebyshev Coefficient: \", Coeff_Fol[Coeff_N])\n",
    "\n",
    "Dataset = pd.DataFrame()\n",
    "\n",
    "\n",
    "for name in FamilyList:\n",
    "    \n",
    "    Temp = pd.read_csv(name)\n",
    "    Temp['TARGET'] = Label[name]\n",
    "    Dataset = Dataset.append(Temp, ignore_index= True)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "os.chdir(dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA ANALYSIS**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ML TRAINING**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Classification Report : Support Vector Machine\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        53\n",
      "           1    1.00000   1.00000   1.00000        47\n",
      "\n",
      "    accuracy                        1.00000       100\n",
      "   macro avg    1.00000   1.00000   1.00000       100\n",
      "weighted avg    1.00000   1.00000   1.00000       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = Dataset.loc[:,'CC_1':f'CC_{str(Coeff_Fol[Coeff_N])}']\n",
    "Y = Dataset.loc[:,'TARGET']\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size= 0.40, random_state=7823, stratify= Y)\n",
    "\n",
    "SVM(X_train,Y_train.to_numpy(), X_validation, Y_validation.to_numpy(), Coeff=Coeff_Fol[Coeff_N], Interval=L[IntervalNo])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Person_identification_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba7e47fdde9fb7b821f6c46db07941d2cd2eb51a9a133aa80525f26ffa6806f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
