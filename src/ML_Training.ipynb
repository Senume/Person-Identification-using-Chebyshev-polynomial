{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IMPORT LIBRARY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 12:02:18.143481: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-20 12:02:19.590817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/senume/anaconda3/envs/Person_identification_Env/lib/\n",
      "2023-02-20 12:02:19.590980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/senume/anaconda3/envs/Person_identification_Env/lib/\n",
      "2023-02-20 12:02:19.590990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/senume/Project/Research/Person-Identification-using-Chebyshev-polynomial\n"
     ]
    }
   ],
   "source": [
    "import os, warnings, math\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning Model \n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report,roc_curve,auc,average_precision_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Deep learning Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Directory Path Saving\n",
    "os.chdir('..')\n",
    "dir = os.getcwd()\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FUNCTION DEFINITION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def SVM(X_Dataset,Y_Dataset, X_validation, Y_validation):\n",
    "  # Normally, C = 1 and gamma = 'scale' are default values\n",
    "  # C controls how wide the margin will be with respect to how many misclassification we are allowing\n",
    "  # C is increasing --> reduce the size of the margin and fewer misclassification and vice versa\n",
    "\n",
    "  param_grid = [\n",
    "      {'C': [0.5, 1, 2, 3, 4, 5],\n",
    "      'gamma': ['scale', 0.5, 0.125, 1],\n",
    "      'kernel': ['rbf', 'linear', 'poly', 'sigmoid']},\n",
    "  ]\n",
    "\n",
    "\n",
    "\n",
    "  optimal_params = GridSearchCV(SVC(),\n",
    "                              param_grid,\n",
    "                              scoring='f1_weighted',\n",
    "                              cv=StratifiedKFold(5))\n",
    "\n",
    "  optimal_params.fit(X_Dataset, Y_Dataset)\n",
    "  print(optimal_params.best_params_)\n",
    "\n",
    "  #svm\n",
    "  C = optimal_params.best_params_['C']\n",
    "  gamma = optimal_params.best_params_['gamma']\n",
    "  kernel = optimal_params.best_params_['kernel']\n",
    "\n",
    "  svm = SVC(C=C, gamma=gamma, kernel=kernel)\n",
    "  svm.fit(X_Dataset, Y_Dataset)\n",
    "\n",
    "  # predict the response\n",
    "  svm_y_pred = svm.predict(X_validation)\n",
    "\n",
    "  # Classification Report for the Support Vector Machine Model\n",
    "  print(\"Classification Report : Support Vector Machine\")\n",
    "  classRep = classification_report(Y_validation, svm_y_pred, digits=2)\n",
    "  print(classRep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOADING DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chebyshev Coefficent ['20', '30', '40', '70', '50', '100', '60', '80', '90', '10']\n",
      "Reading Dataset of Chebyshev Coefficient:  10\n"
     ]
    }
   ],
   "source": [
    "os.chdir(dir + '/Feature_Dataset')\n",
    "L = os.listdir()\n",
    "\n",
    "# For given Interval Type\n",
    "os.chdir(L[0])\n",
    "\n",
    "# Selecting Coefficient_Count Folder \n",
    "Coeff_Fol = os.listdir()\n",
    "print(\"Chebyshev Coefficent\",Coeff_Fol)\n",
    "os.chdir(Coeff_Fol[9])\n",
    "\n",
    "# Patient List\n",
    "PatientList =  os.listdir()\n",
    "\n",
    "# Label Specifying Each Patient\n",
    "Label = {}\n",
    "\n",
    "for n in range(0,len(PatientList)):\n",
    "    Label[PatientList[n]] = n\n",
    "\n",
    "# Spliting the Person into Family List and New Individual List\n",
    "N = len(PatientList)\n",
    "FamilyList_EndIndex = int(math.ceil((70/100)*N))\n",
    "FamilyList = PatientList[:FamilyList_EndIndex]\n",
    "NewIdividualList = PatientList[FamilyList_EndIndex:]\n",
    "\n",
    "\n",
    "# Reading Dataset\n",
    "print(\"Reading Dataset of Chebyshev Coefficient: \", Coeff_Fol[9])\n",
    "\n",
    "Dataset = pd.DataFrame()\n",
    "\n",
    "for name in FamilyList:\n",
    "    Temp = pd.read_csv(name)\n",
    "    Temp['TARGET'] = Label[name]\n",
    "    Dataset = Dataset.append(Temp, ignore_index= True)\n",
    "\n",
    "\n",
    "os.chdir(dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA ANALYSIS**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ML TRAINING**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Classification Report : Support Vector Machine\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86        53\n",
      "           1       0.83      0.40      0.54        47\n",
      "           2       0.86      0.92      0.89        62\n",
      "           3       0.92      0.97      0.94        78\n",
      "           4       0.89      1.00      0.94        58\n",
      "           5       0.99      0.95      0.97       176\n",
      "           6       0.71      0.82      0.76        94\n",
      "           7       0.94      0.96      0.95        51\n",
      "           8       0.57      0.04      0.07       100\n",
      "           9       0.73      0.66      0.69        89\n",
      "          10       1.00      0.98      0.99        57\n",
      "          11       0.97      0.89      0.93        73\n",
      "          12       0.95      0.77      0.85        52\n",
      "          13       0.92      0.56      0.70        39\n",
      "          14       0.57      0.78      0.66       146\n",
      "          15       0.80      0.55      0.65        60\n",
      "          16       0.42      0.42      0.42        48\n",
      "          17       0.98      0.94      0.96        51\n",
      "          18       0.76      0.76      0.76        51\n",
      "          19       1.00      0.91      0.95        45\n",
      "          20       0.66      0.89      0.76       381\n",
      "          21       0.93      0.85      0.89        66\n",
      "          22       0.00      0.00      0.00        49\n",
      "          23       0.80      0.48      0.60        42\n",
      "          24       0.88      0.95      0.91        78\n",
      "          25       0.89      0.30      0.45        53\n",
      "          26       0.97      0.98      0.98        61\n",
      "          27       0.86      0.84      0.85        51\n",
      "          28       0.98      0.87      0.92        62\n",
      "          29       1.00      1.00      1.00        72\n",
      "          30       0.96      0.93      0.94        54\n",
      "          31       0.66      0.63      0.65        49\n",
      "          32       0.88      0.99      0.93       160\n",
      "          33       0.65      0.93      0.77       239\n",
      "          34       0.84      0.93      0.88        60\n",
      "          35       0.00      0.00      0.00        44\n",
      "          36       0.95      0.88      0.91        64\n",
      "\n",
      "    accuracy                           0.79      3015\n",
      "   macro avg       0.80      0.75      0.76      3015\n",
      "weighted avg       0.78      0.79      0.77      3015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = Dataset.loc[:,'CC_1':'CC_10']\n",
    "Y = Dataset.loc[:,'TARGET']\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size= 0.40, random_state=7823, stratify= Y)\n",
    "\n",
    "SVM(X_train,Y_train.to_numpy(), X_validation, Y_validation.to_numpy())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Person_identification_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba7e47fdde9fb7b821f6c46db07941d2cd2eb51a9a133aa80525f26ffa6806f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
